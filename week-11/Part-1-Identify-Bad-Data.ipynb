{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0047d5fa-998b-4b10-a6a2-6da1797b7f39",
   "metadata": {},
   "source": [
    "# Identify Bad Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807de7ec-7260-46ca-a7cd-43b36ff47569",
   "metadata": {},
   "source": [
    "Data can sometimes be flawed. Multiple human hands will input some of it into computer systems, leading to data entry errors or inconsistencies across different individuals. The data quality may also be lost due to translation across different formats or careless consolidating. Ultimately, these discordances will affect any type of process or analysis done down the line. This is one of the primary reasons that data cleansing is so important in data preparation. However, only detecting errors is not the main goal. It also involves knowing which information to include to give a good meaning to any kind of insight derived, especially those used in business decisions.\n",
    "\n",
    "In this section and the next, you'll learn to identify and address issues with missing values, outliers, and unnecessary and inconsistent data. This section focuses on identification and the next focuses on remediation. \n",
    "\n",
    "The scenario for this section is that you have been asked by the head of recruiting for a tech company to analyze the data science jobs advertised on LinkedIn to predict the most competitive salary bands the company should be offering to employees or new hires to attract/retain talent. After web-scraping the information from LinkedIn, we first need to prepare the dataset as it was web-scraped, and there are no guarantees as to the quality.\n",
    "\n",
    "In this section, we are going to use pandas and matplotlib (specifically the pyplot submodule), so we'll start by importing those libraries using aliases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a614dab-ca99-47c3-bd81-81ef5fa98a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25457333",
   "metadata": {},
   "source": [
    "Letâ€™s import and preview the web-scraped LinkedIn dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e0a61c-228f-4e5f-8002-5beb97448eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>onsite_remote</th>\n",
       "      <th>salary</th>\n",
       "      <th>sign_on_bonus</th>\n",
       "      <th>annual_bonus</th>\n",
       "      <th>location</th>\n",
       "      <th>criteria</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst - Recent Graduate</td>\n",
       "      <td>paypal</td>\n",
       "      <td>At PayPal (NASDAQ: PYPL), we believe that ever...</td>\n",
       "      <td>onsite</td>\n",
       "      <td>$75,000.00\\n            -\\n            $95,000.00</td>\n",
       "      <td>9000</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>Buffalo-Niagara Falls Area</td>\n",
       "      <td>[{'Seniority level': 'Not Applicable'}, {'Empl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Recent Graduate</td>\n",
       "      <td>paypal</td>\n",
       "      <td>At PayPal (NASDAQ: PYPL), we believe that ever...</td>\n",
       "      <td>onsite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>[{'Seniority level': 'Not Applicable'}, {'Empl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>paypal</td>\n",
       "      <td>At PayPal (NASDAQ: PYPL), we believe that ever...</td>\n",
       "      <td>onsite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>[{'Seniority level': 'Not Applicable'}, {'Empl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>At PayPal (NASDAQ: PYPL), we believe that ever...</td>\n",
       "      <td>onsite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>Illinois, United States</td>\n",
       "      <td>[{'Seniority level': 'Not Applicable'}, {'Empl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entry-Level Data Analyst</td>\n",
       "      <td>The Federal Savings Bank</td>\n",
       "      <td>The Federal Savings Bank, a national bank and ...</td>\n",
       "      <td>onsite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>[{'Seniority level': 'Entry level'}, {'Employm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title                   company  \\\n",
       "0  Data Analyst - Recent Graduate                    paypal   \n",
       "1  Data Analyst - Recent Graduate                    paypal   \n",
       "2                    Data Analyst                    paypal   \n",
       "3                    Data Analyst                    PayPal   \n",
       "4        Entry-Level Data Analyst  The Federal Savings Bank   \n",
       "\n",
       "                                         description onsite_remote  \\\n",
       "0  At PayPal (NASDAQ: PYPL), we believe that ever...        onsite   \n",
       "1  At PayPal (NASDAQ: PYPL), we believe that ever...        onsite   \n",
       "2  At PayPal (NASDAQ: PYPL), we believe that ever...        onsite   \n",
       "3  At PayPal (NASDAQ: PYPL), we believe that ever...        onsite   \n",
       "4  The Federal Savings Bank, a national bank and ...        onsite   \n",
       "\n",
       "                                              salary  sign_on_bonus  \\\n",
       "0  $75,000.00\\n            -\\n            $95,000.00           9000   \n",
       "1                                                NaN           4000   \n",
       "2                                                NaN           2000   \n",
       "3                                                NaN           3000   \n",
       "4                                                NaN           4000   \n",
       "\n",
       "   annual_bonus                    location  \\\n",
       "0        2400.0  Buffalo-Niagara Falls Area   \n",
       "1        5400.0                San Jose, CA   \n",
       "2        1200.0        Texas, United States   \n",
       "3        1800.0     Illinois, United States   \n",
       "4        2400.0                 Chicago, IL   \n",
       "\n",
       "                                            criteria posted_date  \n",
       "0  [{'Seniority level': 'Not Applicable'}, {'Empl...         NaN  \n",
       "1  [{'Seniority level': 'Not Applicable'}, {'Empl...         NaN  \n",
       "2  [{'Seniority level': 'Not Applicable'}, {'Empl...         NaN  \n",
       "3  [{'Seniority level': 'Not Applicable'}, {'Empl...         NaN  \n",
       "4  [{'Seniority level': 'Entry level'}, {'Employm...         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the CSV file into a pandas DataFrame \n",
    "jobs = pd.read_csv(\"../datasets/li-jobs-usa.csv\")\n",
    "\n",
    "# display the first five rows\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1ddc6-7502-4b5e-bc4c-a71a29ce13b9",
   "metadata": {},
   "source": [
    "### Part I: Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd2773",
   "metadata": {},
   "source": [
    "A quick way to find the columns in our dataset that have missing values, is to use the `info()` method to display information about the DataFrame like this: \n",
    "\n",
    "`df_name.info()`\n",
    "\n",
    "So let's look at the information for our LinkedIn dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25408dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display DataFrame information\n",
    "jobs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048a50e",
   "metadata": {},
   "source": [
    "- `RangeIndex` indicates the total number of rows or entries in the DataFrame, and we see that is 2851 entries.\n",
    "- The Non-Null Count shows the count of non-null (non-missing) values for each column.\n",
    "- We see we have some potentially problematic non-null counts:\n",
    "    - `salary`: 934/2851,\n",
    "    - `annual_bonus`: 2843/2851,\n",
    "    - `location`: 2820/2851\n",
    "    - `posted_date`: 570/2851.\n",
    "\n",
    "\n",
    "- Remember, what we're trying to do is predict salary bands, so the fact that `salary` is missing so much information is a little disconcerting. \n",
    "- Having identified that we think we have a problem here, let's get a handle on the degree of the problem.\n",
    "- The `isnull()` method can be used in conjunction with the familiar `mean()` method to find the percentage of missing values in each problematic column:\n",
    "\n",
    "`df_name[[\"variable_name\", \"variable_name\", \"variable_name\"]].isnull().mean()` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14040fa4-a259-4eb3-98cf-a6cefc361e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a DataFrame of boolean values with True for missing values and False if there is not a missing value at that position:\n",
    "jobs_missing = jobs[['salary', 'annual_bonus', 'location', 'posted_date']]\n",
    "\n",
    "#Calculate the percentage of missing data for each column\n",
    "missing_percentages = jobs_missing.isnull().mean() * 100\n",
    "\n",
    "missing_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1eb4a",
   "metadata": {},
   "source": [
    "Our `salary` variable is missing in 67% of cases! That's a lot for a column that we are directly interested in. We'll see some options for what to do about missing data in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921dfe4-c658-4e94-8080-6213358242a7",
   "metadata": {},
   "source": [
    "### Part II. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d10af",
   "metadata": {},
   "source": [
    "An outlier is a term used in statistics to describe a data point or points that significantly differ from the other data points in a data set. They are unusually large or small and hence stand out from the rest of the data. \n",
    "\n",
    "To understand this concept, let's consider a simple example:\n",
    "\n",
    "Let's say you're a teacher and you have ten students. You give them a test and the scores are as follows:\n",
    "\n",
    "Student 1: 85\n",
    "\n",
    "Student 2: 90\n",
    "\n",
    "Student 3: 88\n",
    "\n",
    "Student 4: 92\n",
    "\n",
    "Student 5: 87\n",
    "\n",
    "Student 6: 91\n",
    "\n",
    "Student 7: 100\n",
    "\n",
    "Student 8: 86\n",
    "\n",
    "Student 9: 89\n",
    "\n",
    "Student 10: 250\n",
    "\n",
    "In this case, most of the scores are in the range of 85-100, which seems normal. However, the score of 250 for Student 10 is much higher than the rest. This would be considered an outlier because it is significantly different from the other scores.\n",
    "\n",
    "Detecting and managing outliers is an important part of data analysis as they can heavily skew results and interpretations, and could potentially indicate issues with data collection or entry. In some cases, outliers may be excluded from data analyses, but in others, they could provide valuable information and thus would be kept and examined further. It's important to understand the reasons behind an outlier before deciding how to handle it.\n",
    "\n",
    "To identify outliers, the easiest way to get started is with boxplots. Our handy dandy `boxplot` method in matplotlib can give us a nice picture, like this:\n",
    "\n",
    "`plt.boxplot(df_name['variable_name'])`\n",
    "\n",
    "- And it's alwats a good idea to give your viewers some clue what they're looking at with titles, axis labels etc:\n",
    "\n",
    "\n",
    "`plt.title('Title')`\n",
    "`plt.ylabel(\"y-axis label\")`\n",
    "\n",
    "The boxplot of the 'sign_on_bonus' variable in the jobs data shows us two outliers (the dots in the figure: 9000 and 8000 USD):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d948d-8dc8-4372-9d35-c543033e8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boxplot \n",
    "plt.boxplot(jobs['sign_on_bonus'])\n",
    "\n",
    "# Title\n",
    "plt.title('Boxplot for sign_on_bonus')\n",
    "\n",
    "# label y-axis\n",
    "plt.ylabel(\"USD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929b32b-7b87-44fb-b043-5862ef9ca81d",
   "metadata": {},
   "source": [
    "To check your data overall, use:\n",
    "\n",
    "`df_name.boxplot()`\n",
    "\n",
    "This will give you boxplots for all numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4d410-ab34-4ae6-af9b-cfbbf6b358dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.boxplot()\n",
    "plt.title(\"Boxplot of `jobs` DataFrame Variables\")\n",
    "plt.ylabel(\"USD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16ea0f-96c0-4aea-9b95-79e1db6795f4",
   "metadata": {},
   "source": [
    "#### Inter Quartile Range (IQR)\n",
    "\n",
    "Calculating IQR is one of the main statistical tecniques used to identify outliers.  \n",
    "\n",
    "\n",
    "##### What's a Quartile???\n",
    "\n",
    "In calculating IQR, we use this funny-sounding thing called quartiles. Quartiles split our data into four equal parts. The first quartile (Q1) is the value below which 25% of our data falls, and the third quartile (Q3) is the value below which 75% of our data falls. For finding outliers, we first calculate the Interquartile Range (IQR) by subtracting Q1 from Q3. So we need to find Q1 and Q3. In pandas, the `quantile()` method is used to find the value at any percentile. To find Q1, we use `quantile(0.25)`, etc:\n",
    "\n",
    "\n",
    "`Q1 = df_name['variable_name'].quantile(0.25)`\n",
    "\n",
    "`Q3 = df_name['variable_name'].quantile(0.75)`\n",
    "\n",
    "`IQR = Q3 - Q1`\n",
    "\n",
    "Next we need to define the boundaries for outliers. The rule of thumb is outliers are any value above Q3 + 1.5IQR or below Q1 - 1.5IQR:\n",
    "\n",
    "\n",
    "`lower_bound = Q1 - 1.5 * IQR`\n",
    "\n",
    "`upper_bound = Q3 + 1.5 * IQR`\n",
    "\n",
    "Finally, we use our rockin pandas skills to select values from the data:\n",
    "\n",
    "\n",
    "`outliers = df_name['variable_name'][(df_name['variable_name'] < lower_bound) | (df_name['variable_name'] > upper_bound)]`\n",
    "\n",
    "\n",
    "Let's find the outliers in the 'sign_on_bonus' data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the IQR\n",
    "\n",
    "Q1 = jobs['sign_on_bonus'].quantile(0.25)\n",
    "Q3 = jobs['sign_on_bonus'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the boundaries for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify the outliers\n",
    "outliers = jobs['sign_on_bonus'][(jobs['sign_on_bonus'] < lower_bound) | (jobs['sign_on_bonus'] > upper_bound)] \n",
    "\n",
    " # display the outliers\n",
    "outliers\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
