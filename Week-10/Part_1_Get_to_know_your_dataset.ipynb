{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0047d5fa-998b-4b10-a6a2-6da1797b7f39",
   "metadata": {},
   "source": [
    "# Getting to know your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed30841",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6fbca",
   "metadata": {},
   "source": [
    "The goal of the Business Understanding step of the Data Science Process is to develop a clear statement of the question or problem you are trying to solve. Once you have that problem clarified, you're ready to dig into your data in the **Data Understanding** step:\n",
    "\n",
    "The Data Understanding step of the Data Science Process involves building an initial understanding of your data by exploring and visualizing your data. We'll address visualizing next week.\n",
    "\n",
    "This week, we'll discuss your intial exploration of the data with the pandas library. \n",
    "\n",
    "That initial exploration includes:\n",
    "\n",
    "1. Collecting and loading the data:\n",
    "- Gather the data you need from relevant sources, such as databases, files, or APIs. \n",
    "- Load the data into a pandas DataFrame\n",
    "\n",
    "2. Exploring the data: \n",
    "- Look at the organization of your data, such as \n",
    "\t- the number of rows and columns\n",
    "\t- variable names\n",
    "\t- data types.\n",
    "- Familiarize yourself with the data by looking at a few rows or records.\n",
    "- This will give you an idea of the size and complexity of the dataset and is an important intial sanity check.\n",
    "\n",
    "\n",
    "3. Summarizing the data: \n",
    "- Generate basic statistics (such as counts, averages, and percentages) for each variable or feature. - This will help you understand the distribution of the data and identify potential issues, like outliers or missing values.\n",
    "\n",
    "\n",
    "Next week , we'll work on creating visualizations of the data with the matplotlib library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc81d02-fed0-48e0-beb2-ce4c4e26e59a",
   "metadata": {},
   "source": [
    "### 1.1 Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd7772-3c9d-473d-8206-82885a081694",
   "metadata": {},
   "source": [
    "In this section, we'll see how to read data into a DataFrame from CSV (comma-separated values) files, one of the most common data formats you'll encounter. \n",
    "\n",
    "\n",
    "Imagine your boss at a talent agency emails you the `spotify-dataset.csv` file. The file is a dataset of songs and their characteristics that she downloaded from Spotify. She also sends a data dictionary so you can reference the variables.\n",
    "\n",
    "The data dictionary:\n",
    "\n",
    "- `title`: name of the Track \n",
    "- `artist`: name of the Artist \n",
    "- `year`: release year of the track \n",
    "- `bpm`: beats per minute; the tempo of the song \n",
    "- `en`: energy; the higher the value, the more energetic a song \n",
    "- `dnce`: danceability, the higher the value, the easier it is to dance to this song\n",
    "- `loud`: loudness; the higher the value, the louder the song\n",
    "- `val`: valence; the higher the value, the more positive mood for the song\n",
    "- `dur`: duration; length of the song\n",
    "- `acous`: acoustic; the higher the value the more acoustic the song is\n",
    "- `speech`: speechiness; the higher the value the more spoken words the song contains \n",
    "- `pop`: popularity; the higher the value the more popular the song is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aab988",
   "metadata": {},
   "source": [
    "#### Viewing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c2b55",
   "metadata": {},
   "source": [
    "To import the `spotify-dataset.csv` file as a DataFrame, we'll use the `read_csv()` method like this:\n",
    "\n",
    "`dataframe_name = pd.read_csv(filename)`\n",
    " \n",
    "The `read_csv()` method will read the file specified by the filename, parse the data contained within that file, and store it all in a DataFrame. Let's import the CSV file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the CSV file into a DataFrame\n",
    "music = pd.read_csv(\"../datasets/spotify-dataset.csv\")\n",
    "\n",
    "# display the DataFrame \n",
    "music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e2c13",
   "metadata": {},
   "source": [
    "### 1.2 Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fddd1",
   "metadata": {},
   "source": [
    "#### Previewing the DataFrame\n",
    "\n",
    "- Ensuring the correctness of a .csv file post-import can help identify any discrepancies present in the imported data. \n",
    "- This precautionary measure prevents us from diving into data analysis and subsequently encountering unexpected outcomes due to incomplete data or the file not adhering to the standard comma-separated values format.\n",
    "\n",
    "- A good place to start is with the `.shape` attribute that allows you to quickly check the dimensions (number of rows and columns) of your DataFrame.\n",
    "- This can help you confirm that you've loaded your data correctly. For example, if you were expecting to load a dataset with 100 rows and 5 columns, and df.shape returns (100, 5), that's a good sign that your data has been loaded correctly. If it returns something different, it may mean there was an error when importing the file, or that the file's structure wasn't what you expected.\n",
    "- Another way it can be helpful is in identifying missing data:\n",
    "    - If you remove or filter rows with missing data, checking df.shape again can tell you how many rows were removed.\n",
    "\n",
    "Here is how you use it:\n",
    "\n",
    "`df_name.shape` \n",
    "\n",
    "NOTE: `.shape` is an attribute, not a method, so you don't use parentheses with it: `df.shape`, not `df.shape()`.\n",
    "\n",
    "\n",
    "Letâ€™s take a look at our music dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eca51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dimensions of your DataFrame\n",
    "music.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04583d2d-ebe9-43b7-9c52-a7f4b07d0ce8",
   "metadata": {},
   "source": [
    "#### Preview the DataFrame\n",
    "\n",
    "After importing data from a .csv file, using the `head()` and `tail()` methods to look at the first few and last few rows of your DataFrame can help you visually confirm that your data has been loaded correctly. You can check things like:\n",
    "\n",
    "- The column names are correct.\n",
    "- The data in each column is of the right type (e.g., text, number).\n",
    "- The data doesn't contain unexpected values or errors.\n",
    "\n",
    "For example, suppose you're expecting a DataFrame with the columns 'Name', 'Age', and 'City'. After loading your DataFrame, you can use `df.head()` to quickly check that these columns exist and contain the data types you expect, i.e., 'Name' is text, 'Age' is numerical and 'City' is text.\n",
    "\n",
    "\n",
    "Use the `head()` method like this to see the first 5 rows:\n",
    " \n",
    "`df_name.head()`\n",
    "\n",
    "You can also specify the number of rows: \n",
    "\n",
    "`df_name.head(n=number_of_rows)`\n",
    "\n",
    "\n",
    "Similarly, the tail() method shows the last 'n' rows of the DataFrame:\n",
    "\n",
    "`df_name.tail()`\n",
    " \n",
    "Let's check the `music` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec839c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# return first five rows\n",
    "music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return bottom five rows\n",
    "music.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return first ten rows\n",
    "music.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d414fdad-e9a9-4f49-b3cc-59105abf2095",
   "metadata": {},
   "source": [
    "### 1.3 Summarizing the DataFrame\n",
    "\n",
    "- Imagine you've just received a big set of data and you want to get an overall idea of what it looks like.\n",
    "- The `describe()` method is a one-stop-shop for getting a quick summary of your data.\n",
    "- When you apply describe() to your dataset, it calculates a bunch of different things all at once. \n",
    "    - the count (how many items there are)\n",
    "    - the mean (the average)\n",
    "    - the standard deviation (how spread out the data is)\n",
    "    - the minimum and maximum values, and\n",
    "    - the quartiles (which split the data into four equal parts).\n",
    "\n",
    "\n",
    "You can apply  `describe()` to the entire DataFrame like this:\n",
    "\n",
    "`dataframe_name.describe()`\n",
    "\n",
    "Or you can apply it to one variable like this:\n",
    "\n",
    "`dataframe_name['column_name'].describe()`\n",
    "\n",
    "Let's get a first pass look at the music DataFramewith describe():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8b3b0-0ae5-4d34-be78-36172be72f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the DataFrame\n",
    "music.describe()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c63960b54d63937ce411e8039d360c6ab8230fb7ef9e5a2e3258b7a88ac121c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
